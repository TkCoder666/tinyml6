{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training set together with augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x / 255.0 for x in[0.507, 0.487, 0.441]],\n",
    "                                     std=[x / 255.0 for x in [0.267, 0.256, 0.276]])\n",
    "])\n",
    "\n",
    "# Normalize test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x / 255.0 for x in[0.507, 0.487, 0.441]],\n",
    "                                     std=[x / 255.0 for x in [0.267, 0.256, 0.276]])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "num_epochs = 40\n",
    "momentum=0.9\n",
    "weight_decay=1e-5\n",
    "batch_size_train=256\n",
    "batch_size_test=256\n",
    "batch_size = 256\n",
    "trainset = torchvision.datasets.CIFAR100(root = \"./data\",\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size_train, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root = \"./data\",\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size_test, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \",device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "    \"\"\"\n",
    "\n",
    "    #BasicBlock and BottleNeck block\n",
    "    #have different output size\n",
    "    #we use class attribute expansion\n",
    "    #to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "        )\n",
    "\n",
    "        #shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        #the shortcut output dimension is not the same with residual function\n",
    "        #use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.LeakyReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "    \"\"\"\n",
    "    expansion = 2\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.LeakyReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_block, num_classes=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        #we use a different inputsize than the original paper\n",
    "        #so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
    "        contain more than one residual block\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block\n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = self.dropout(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def resnet18():\n",
    "    \"\"\" return a ResNet 18 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "    \"\"\" return a ResNet 34 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" return a ResNet 50 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
    "\n",
    "def resnet101():\n",
    "    \"\"\" return a ResNet 101 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    \"\"\" return a ResNet 152 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model = model.cuda()# I choose ResNet50. Because of Memory :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "conv1.0.weight \t 1728\n",
      "conv1.1.weight \t 64\n",
      "conv1.1.bias \t 64\n",
      "conv2_x.0.residual_function.0.weight \t 4096\n",
      "conv2_x.0.residual_function.1.weight \t 64\n",
      "conv2_x.0.residual_function.1.bias \t 64\n",
      "conv2_x.0.residual_function.3.weight \t 36864\n",
      "conv2_x.0.residual_function.4.weight \t 64\n",
      "conv2_x.0.residual_function.4.bias \t 64\n",
      "conv2_x.0.residual_function.6.weight \t 8192\n",
      "conv2_x.0.residual_function.7.weight \t 128\n",
      "conv2_x.0.residual_function.7.bias \t 128\n",
      "conv2_x.0.shortcut.0.weight \t 8192\n",
      "conv2_x.0.shortcut.1.weight \t 128\n",
      "conv2_x.0.shortcut.1.bias \t 128\n",
      "conv2_x.1.residual_function.0.weight \t 8192\n",
      "conv2_x.1.residual_function.1.weight \t 64\n",
      "conv2_x.1.residual_function.1.bias \t 64\n",
      "conv2_x.1.residual_function.3.weight \t 36864\n",
      "conv2_x.1.residual_function.4.weight \t 64\n",
      "conv2_x.1.residual_function.4.bias \t 64\n",
      "conv2_x.1.residual_function.6.weight \t 8192\n",
      "conv2_x.1.residual_function.7.weight \t 128\n",
      "conv2_x.1.residual_function.7.bias \t 128\n",
      "conv2_x.2.residual_function.0.weight \t 8192\n",
      "conv2_x.2.residual_function.1.weight \t 64\n",
      "conv2_x.2.residual_function.1.bias \t 64\n",
      "conv2_x.2.residual_function.3.weight \t 36864\n",
      "conv2_x.2.residual_function.4.weight \t 64\n",
      "conv2_x.2.residual_function.4.bias \t 64\n",
      "conv2_x.2.residual_function.6.weight \t 8192\n",
      "conv2_x.2.residual_function.7.weight \t 128\n",
      "conv2_x.2.residual_function.7.bias \t 128\n",
      "conv3_x.0.residual_function.0.weight \t 16384\n",
      "conv3_x.0.residual_function.1.weight \t 128\n",
      "conv3_x.0.residual_function.1.bias \t 128\n",
      "conv3_x.0.residual_function.3.weight \t 147456\n",
      "conv3_x.0.residual_function.4.weight \t 128\n",
      "conv3_x.0.residual_function.4.bias \t 128\n",
      "conv3_x.0.residual_function.6.weight \t 32768\n",
      "conv3_x.0.residual_function.7.weight \t 256\n",
      "conv3_x.0.residual_function.7.bias \t 256\n",
      "conv3_x.0.shortcut.0.weight \t 32768\n",
      "conv3_x.0.shortcut.1.weight \t 256\n",
      "conv3_x.0.shortcut.1.bias \t 256\n",
      "conv3_x.1.residual_function.0.weight \t 32768\n",
      "conv3_x.1.residual_function.1.weight \t 128\n",
      "conv3_x.1.residual_function.1.bias \t 128\n",
      "conv3_x.1.residual_function.3.weight \t 147456\n",
      "conv3_x.1.residual_function.4.weight \t 128\n",
      "conv3_x.1.residual_function.4.bias \t 128\n",
      "conv3_x.1.residual_function.6.weight \t 32768\n",
      "conv3_x.1.residual_function.7.weight \t 256\n",
      "conv3_x.1.residual_function.7.bias \t 256\n",
      "conv3_x.2.residual_function.0.weight \t 32768\n",
      "conv3_x.2.residual_function.1.weight \t 128\n",
      "conv3_x.2.residual_function.1.bias \t 128\n",
      "conv3_x.2.residual_function.3.weight \t 147456\n",
      "conv3_x.2.residual_function.4.weight \t 128\n",
      "conv3_x.2.residual_function.4.bias \t 128\n",
      "conv3_x.2.residual_function.6.weight \t 32768\n",
      "conv3_x.2.residual_function.7.weight \t 256\n",
      "conv3_x.2.residual_function.7.bias \t 256\n",
      "conv3_x.3.residual_function.0.weight \t 32768\n",
      "conv3_x.3.residual_function.1.weight \t 128\n",
      "conv3_x.3.residual_function.1.bias \t 128\n",
      "conv3_x.3.residual_function.3.weight \t 147456\n",
      "conv3_x.3.residual_function.4.weight \t 128\n",
      "conv3_x.3.residual_function.4.bias \t 128\n",
      "conv3_x.3.residual_function.6.weight \t 32768\n",
      "conv3_x.3.residual_function.7.weight \t 256\n",
      "conv3_x.3.residual_function.7.bias \t 256\n",
      "conv4_x.0.residual_function.0.weight \t 65536\n",
      "conv4_x.0.residual_function.1.weight \t 256\n",
      "conv4_x.0.residual_function.1.bias \t 256\n",
      "conv4_x.0.residual_function.3.weight \t 589824\n",
      "conv4_x.0.residual_function.4.weight \t 256\n",
      "conv4_x.0.residual_function.4.bias \t 256\n",
      "conv4_x.0.residual_function.6.weight \t 131072\n",
      "conv4_x.0.residual_function.7.weight \t 512\n",
      "conv4_x.0.residual_function.7.bias \t 512\n",
      "conv4_x.0.shortcut.0.weight \t 131072\n",
      "conv4_x.0.shortcut.1.weight \t 512\n",
      "conv4_x.0.shortcut.1.bias \t 512\n",
      "conv4_x.1.residual_function.0.weight \t 131072\n",
      "conv4_x.1.residual_function.1.weight \t 256\n",
      "conv4_x.1.residual_function.1.bias \t 256\n",
      "conv4_x.1.residual_function.3.weight \t 589824\n",
      "conv4_x.1.residual_function.4.weight \t 256\n",
      "conv4_x.1.residual_function.4.bias \t 256\n",
      "conv4_x.1.residual_function.6.weight \t 131072\n",
      "conv4_x.1.residual_function.7.weight \t 512\n",
      "conv4_x.1.residual_function.7.bias \t 512\n",
      "conv4_x.2.residual_function.0.weight \t 131072\n",
      "conv4_x.2.residual_function.1.weight \t 256\n",
      "conv4_x.2.residual_function.1.bias \t 256\n",
      "conv4_x.2.residual_function.3.weight \t 589824\n",
      "conv4_x.2.residual_function.4.weight \t 256\n",
      "conv4_x.2.residual_function.4.bias \t 256\n",
      "conv4_x.2.residual_function.6.weight \t 131072\n",
      "conv4_x.2.residual_function.7.weight \t 512\n",
      "conv4_x.2.residual_function.7.bias \t 512\n",
      "conv4_x.3.residual_function.0.weight \t 131072\n",
      "conv4_x.3.residual_function.1.weight \t 256\n",
      "conv4_x.3.residual_function.1.bias \t 256\n",
      "conv4_x.3.residual_function.3.weight \t 589824\n",
      "conv4_x.3.residual_function.4.weight \t 256\n",
      "conv4_x.3.residual_function.4.bias \t 256\n",
      "conv4_x.3.residual_function.6.weight \t 131072\n",
      "conv4_x.3.residual_function.7.weight \t 512\n",
      "conv4_x.3.residual_function.7.bias \t 512\n",
      "conv4_x.4.residual_function.0.weight \t 131072\n",
      "conv4_x.4.residual_function.1.weight \t 256\n",
      "conv4_x.4.residual_function.1.bias \t 256\n",
      "conv4_x.4.residual_function.3.weight \t 589824\n",
      "conv4_x.4.residual_function.4.weight \t 256\n",
      "conv4_x.4.residual_function.4.bias \t 256\n",
      "conv4_x.4.residual_function.6.weight \t 131072\n",
      "conv4_x.4.residual_function.7.weight \t 512\n",
      "conv4_x.4.residual_function.7.bias \t 512\n",
      "conv4_x.5.residual_function.0.weight \t 131072\n",
      "conv4_x.5.residual_function.1.weight \t 256\n",
      "conv4_x.5.residual_function.1.bias \t 256\n",
      "conv4_x.5.residual_function.3.weight \t 589824\n",
      "conv4_x.5.residual_function.4.weight \t 256\n",
      "conv4_x.5.residual_function.4.bias \t 256\n",
      "conv4_x.5.residual_function.6.weight \t 131072\n",
      "conv4_x.5.residual_function.7.weight \t 512\n",
      "conv4_x.5.residual_function.7.bias \t 512\n",
      "conv5_x.0.residual_function.0.weight \t 262144\n",
      "conv5_x.0.residual_function.1.weight \t 512\n",
      "conv5_x.0.residual_function.1.bias \t 512\n",
      "conv5_x.0.residual_function.3.weight \t 2359296\n",
      "conv5_x.0.residual_function.4.weight \t 512\n",
      "conv5_x.0.residual_function.4.bias \t 512\n",
      "conv5_x.0.residual_function.6.weight \t 524288\n",
      "conv5_x.0.residual_function.7.weight \t 1024\n",
      "conv5_x.0.residual_function.7.bias \t 1024\n",
      "conv5_x.0.shortcut.0.weight \t 524288\n",
      "conv5_x.0.shortcut.1.weight \t 1024\n",
      "conv5_x.0.shortcut.1.bias \t 1024\n",
      "conv5_x.1.residual_function.0.weight \t 524288\n",
      "conv5_x.1.residual_function.1.weight \t 512\n",
      "conv5_x.1.residual_function.1.bias \t 512\n",
      "conv5_x.1.residual_function.3.weight \t 2359296\n",
      "conv5_x.1.residual_function.4.weight \t 512\n",
      "conv5_x.1.residual_function.4.bias \t 512\n",
      "conv5_x.1.residual_function.6.weight \t 524288\n",
      "conv5_x.1.residual_function.7.weight \t 1024\n",
      "conv5_x.1.residual_function.7.bias \t 1024\n",
      "conv5_x.2.residual_function.0.weight \t 524288\n",
      "conv5_x.2.residual_function.1.weight \t 512\n",
      "conv5_x.2.residual_function.1.bias \t 512\n",
      "conv5_x.2.residual_function.3.weight \t 2359296\n",
      "conv5_x.2.residual_function.4.weight \t 512\n",
      "conv5_x.2.residual_function.4.bias \t 512\n",
      "conv5_x.2.residual_function.6.weight \t 524288\n",
      "conv5_x.2.residual_function.7.weight \t 1024\n",
      "conv5_x.2.residual_function.7.bias \t 1024\n",
      "fc.weight \t 102400\n",
      "fc.bias \t 100\n",
      "\n",
      "Total \t 16833700\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "print('Trainable parameters:')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, '\\t', param.numel())\n",
    "        total += param.numel()\n",
    "print()\n",
    "print('Total', '\\t', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 0/196\n",
      "epoch: 0 7/196\n",
      "epoch: 0 14/196\n",
      "epoch: 0 21/196\n",
      "[1,    25] loss: 4.781\n",
      "epoch: 0 28/196\n",
      "epoch: 0 35/196\n",
      "epoch: 0 42/196\n",
      "[1,    50] loss: 4.360\n",
      "epoch: 0 49/196\n",
      "epoch: 0 56/196\n",
      "epoch: 0 63/196\n",
      "epoch: 0 70/196\n",
      "[1,    75] loss: 4.192\n",
      "epoch: 0 77/196\n",
      "epoch: 0 84/196\n",
      "epoch: 0 91/196\n",
      "epoch: 0 98/196\n",
      "[1,   100] loss: 4.044\n",
      "epoch: 0 105/196\n",
      "epoch: 0 112/196\n",
      "epoch: 0 119/196\n",
      "[1,   125] loss: 3.941\n",
      "epoch: 0 126/196\n",
      "epoch: 0 133/196\n",
      "epoch: 0 140/196\n",
      "epoch: 0 147/196\n",
      "[1,   150] loss: 3.875\n",
      "epoch: 0 154/196\n",
      "epoch: 0 161/196\n",
      "epoch: 0 168/196\n",
      "[1,   175] loss: 3.788\n",
      "epoch: 0 175/196\n",
      "epoch: 0 182/196\n",
      "epoch: 0 189/196\n",
      "Accuracy train 11 %\n",
      "Accuracy test 11 %\n",
      "epoch: 1 0/196\n",
      "epoch: 1 7/196\n",
      "epoch: 1 14/196\n",
      "epoch: 1 21/196\n",
      "[2,    25] loss: 6.830\n",
      "epoch: 1 28/196\n",
      "epoch: 1 35/196\n",
      "epoch: 1 42/196\n",
      "[2,    50] loss: 3.641\n",
      "epoch: 1 49/196\n",
      "epoch: 1 56/196\n",
      "epoch: 1 63/196\n",
      "epoch: 1 70/196\n",
      "[2,    75] loss: 3.592\n",
      "epoch: 1 77/196\n",
      "epoch: 1 84/196\n",
      "epoch: 1 91/196\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_241004/1320378407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# print every 500 mini batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tinyml/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tinyml/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tinyml/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m                  \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                  \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                  capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tinyml/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tinyml/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "train_acc = []\n",
    "start = time.time()\n",
    "loss_list = []\n",
    "running_loss = 0\n",
    "total_step = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):       \n",
    "        # gpu\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "            \n",
    "        \n",
    "        # backward and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 25 == 24: # print every 500 mini batches\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i+1,running_loss/25))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if i % 7 == 0:\n",
    "            print(\"epoch: {} {}/{}\".format(epoch,i,total_step))\n",
    "\n",
    "\n",
    "    # train\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy train %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    # test\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data      \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)                \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy test %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "end= time.time()\n",
    "stopWatch = end-start\n",
    "print( \"Training is done\")\n",
    "print('Total Training Time (second):',stopWatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['beaver', 'dolphin', 'otter', 'seal', 'whale', \n",
    "'aquarium' ,'fish', 'ray', 'shark', 'trout', \n",
    "'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', \n",
    "'bottles', 'bowls', 'cans', 'cups', 'plates', \n",
    "'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', \n",
    "'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', \n",
    "'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', \n",
    "'bear', 'leopard', 'lion', 'tiger', 'wolf', \n",
    "'bridge', 'castle', 'house', 'road', 'skyscraper', \n",
    "'cloud', 'forest', 'mountain', 'plain', 'sea', \n",
    "'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', \n",
    "'fox', 'porcupine', 'possum', 'raccoon', 'skunk', \n",
    "'crab', 'lobster', 'snail', 'spider', 'worm', \n",
    "'baby', 'boy', 'girl', 'man', 'woman', \n",
    "'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', \n",
    "'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', \n",
    "'maple', 'oak', 'palm', 'pine', 'willow', \n",
    "'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train', \n",
    "'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_label_predictions(model, device, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "actuals, predictions = test_label_predictions(model, device, testloader)\n",
    "print('F1 score: %f' % f1_score(actuals, predictions, average='weighted'))\n",
    "print('Accuracy score: %f' % accuracy_score(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(actuals, predictions)\n",
    "print(cm)\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax = fig.add_subplot(211)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + classes)\n",
    "ax.set_yticklabels([''] + classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actuals, predictions, target_names=classes, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tinyml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc4e0d317d9605a45be200e97ae5d1719a7e19a353a468883bc88fd0452c1206"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
